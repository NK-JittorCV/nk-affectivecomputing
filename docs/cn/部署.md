# 单个视频的推理
## CTEN

使用以下命令进行单个视频的推理：

~~~
bash script/run.sh CTEN test_singlevideo
--video_path your_path
--output_frame_dir your_path
--output_audio_dir your_path
--checkpoint_path your_path
~~~

## 参数说明

- `video_path`：视频帧序列或视频文件的路径。在进行单个视频推理时，该参数为输入视频的路径。  
- `output_frame_dir`：用于存储提取后视频帧的目录。在推理之前，脚本会自动从输入视频中提取视频帧并保存到此目录。  
- `output_audio_dir`：用于存储提取后音频文件（`.mp3` 格式）的目录。在推理之前，脚本会自动从输入视频中提取音频并保存到此目录。  
- `checkpoint_path`：预训练模型权重的路径。

## VAANet

使用以下命令进行单个视频的推理：

~~~
bash script/run.sh VAANet test_singlevideo
--video_path your_path
--output_frame_dir your_path
--output_audio_dir your_path
--checkpoint_path your_path
~~~

## 参数说明

- `video_path`：视频帧序列或视频文件的路径。在进行单个视频推理时，该参数为输入视频的路径。  
- `output_frame_dir`：用于存储提取后视频帧的目录。在推理之前，脚本会自动从输入视频中提取视频帧并保存到此目录。  
- `output_audio_dir`：用于存储提取后音频文件（`.mp3` 格式）的目录。在推理之前，脚本会自动从输入视频中提取音频并保存到此目录。  
- `checkpoint_path`：预训练模型权重的路径。
## TSL-Net

使用 **TSL-Net** 对单个视频进行推理前，需先对该视频进行预处理，包括视频和音频的特征提取：
- **视频特征提取**：  
  使用 I3D 模型提取 RGB 特征。我们使用的预训练模型和实现来自于 [pytorch-i3d](https://github.com/piergiaj/pytorch-i3d)。
- **音频特征提取**：  
  我们使用最常用的音频描述符 —— 梅尔频率倒谱系数（MFCC）进行特征提取。
提取后的 **RGB** 和 **MFCC** 特征均以 `.npy` 格式保存。

关于详细的预处理步骤，请参考 [inference.sh](../../src/TSL/inference.sh)。
完成特征提取后，可使用以下推理命令进行预测：

~~~
bash script/run.sh TSL main_inference
--rgb_path ./src/TSL/tmp/rgb/40_VideoEmotion8_Anger_88.npy
--mfcc_path ./src/TSL/tmp/mfcc/40_VideoEmotion8_Anger_88.npy
--output_path ./src/TSL/outputs/inference
--log_path ./src/TSL/logs/inference
--modal all
--seed 123
--model_file ./src/TSL/models/train/model_seed_123.pth
~~~


### 参数说明

- `rgb_path`：使用 I3D 提取的 `.npy` 格式视频特征路径  
- `mfcc_path`：使用 MFCC 提取的 `.npy` 格式音频特征路径  
- `output_path`：用于存储输出文件的路径，如预测结果或可视化文件  
- `log_path`：用于存储日志文件的路径，用于记录测试过程信息  
- `modal`：输入模态选项。可选值为 `'rgb'`（仅视频）、`'logmfcc'`（仅音频）或 `'all'`（视频 + 音频）  
- `seed`：用于结果复现的随机种子；设为 -1 表示不使用手动设置种子  
- `model_file`：预训练模型文件的路径


