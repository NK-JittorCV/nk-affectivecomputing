# 数据集准备

## VideoEmotion-8

VideoEmotion-8 是一个用于视频级情感识别的基准数据集，包含来自在线视频平台收集的用户生成视频。每个视频依据心理学中经典的情绪分类模型，被标注为 8 类基本情绪之一：愤怒（Anger）、期待（Anticipation）、厌恶（Disgust）、恐惧（Fear）、喜悦（Joy）、悲伤（Sadness）、惊讶（Surprise）和信任（Trust）。该数据集涵盖丰富的真实场景和多样化的情感表达，为情感计算、视频理解及多模态情绪分析等研究任务提供了具有挑战性的重要资源。VideoEmotion-8 被广泛用于评估融合视觉、音频与文本等多模态特征的情感识别模型。

References：[Predicting Emotions in User-Generated Videos](https://cdn.aaai.org/ojs/8724/8724-13-12252-1-2-20201228.pdf )

The dataset structure is as follows：
~~~~
├── VideoEmotion-8
   └── img
       ├── Anger
            ├── 1
                ├── 000001.jpg
                ├── 000002.jpg
                ├── ...
            ├── 2
            ├── 3
            ├── ...
       ├── Anticipation
       ├── Disgust
       ├── Fear
       ├── Joy
       ├── Sadness
       ├── Surprise
       ├── Trust
   └── mp3
       ├── Anger
            ├── 1.mp3
            ├── 2.mp3
            ├── 3.mp3
            ├── ...
       ├── Anticipation
       ├── Disgust
       ├── Fear
       ├── Joy
       ├── Sadness
       ├── Surprise
       ├── Trust
   └── srt (optional, only for MART)
       ├── Anger
            ├── 1.srt
            ├── 2.srt
            ├── 3.srt
            ├── ...
       ├── Anticipation
       ├── Disgust
       ├── Fear
       ├── Joy
       ├── Sadness
       ├── Surprise
       ├── Trust
~~~~

## Ekman6

Ekman-6 是基于保罗·埃克曼（Paul Ekman）提出的六种基本情绪理论构建的情感分类基准数据集，广泛用于情感识别和情感计算研究领域。该数据集通常包含大量图像、音频或视频样本，并将每个样本标注为六种基本情绪之一：愤怒（Anger）、厌恶（Disgust）、恐惧（Fear）、高兴（Happiness）、悲伤（Sadness）和惊讶（Surprise）。这些情绪被认为是跨文化普遍存在的基本情感表达形式。Ekman-6 数据集常用于表情识别、语音情感识别以及多模态情感识别等任务中，支持研究人员开发和评估各种情绪感知模型与算法。

References：[ Heterogeneous Knowledge Transfer in Video Emotion Recognition, Attribution and Summarization](https://ieeexplore.ieee.org/document/7723914 )

The dataset structure is as follows：
~~~~
├── Ekman6
   └── img
       ├── Anger
            ├── 1
                ├── 000001.jpg
                ├── 000002.jpg
                ├── ...
            ├── 2
            ├── 3
            ├── ...
       ├── Disgust
       ├── Fear
       ├── Joy
       ├── Sadness
       ├── Surprise
   └── mp3
       ├── Anger
            ├── 1.mp3
            ├── 2.mp3
            ├── 3.mp3
            ├── ...
       ├── Disgust
       ├── Fear
       ├── Joy
       ├── Sadness
       ├── Surprise
   └── srt (optional, only for MART)
       ├── Anger
            ├── 1.srt
            ├── 2.srt
            ├── 3.srt
            ├── ...
       ├── Disgust
       ├── Fear
       ├── Joy
       ├── Sadness
       ├── Surprise
~~~~

## ERATO

ERATO（Emotional RelAtionship of inTeractiOn）是为“成对情感关系识别”（Pairwise Emotional Relationship Recognition，PERR）任务设计的大规模多模态视频数据集，来源于影视剧中的真实对话片段。该数据集包含 31,182 个视频剪辑，总时长约 203 小时，涵盖视觉、音频和文本（对白/字幕）等多种信息通道。每个视频剪辑聚焦于两名角色之间的情感关系，并分为更细粒度的情感类型（如：敌对、紧张、亲密、中性）和粗粒度的情感类别（正面、中性、负面）。ERATO 数据集结构严谨、场景丰富，为多模态情感理解与关系识别模型提供了极具挑战性的基准资源。

References：[ Pairwise Emotional Relationship Recognition in Drama Videos: Dataset and Benchmark](https://arxiv.org/pdf/2109.11243)

~~~~
├── ERATO
   └── img
       ├── Hostile
            ├── 1
                ├── 000001.jpg
                ├── 000002.jpg
                ├── ...
            ├── 2
            ├── 3
            ├── ...
       ├── Intimate
       ├── Mild
       ├── Neutral
       ├── tense
   └── mp3
       ├── Hostile
            ├── 1.mp3
            ├── 2.mp3
            ├── 3.mp3
            ├── ...
       ├── Intimate
       ├── Mild
       ├── Neutral
       ├── tense
   └── srt (optional, only for MART)
       ├── Hostile
            ├── 1.srt
            ├── 2.srt
            ├── 3.srt
            ├── ...
       ├── Intimate
       ├── Mild
       ├── Neutral
       ├── tense
~~~~

## Affwild2

Aff-Wild2 是当前规模最大、标注最全面的“自然环境下情感识别”基准数据集之一，是在原始 Aff-Wild 数据集的基础上扩展而成的。原始 Aff-Wild 数据集包含约 120 万帧视频，而 Aff-Wild2 进一步新增了 260 名受试者和约 141 万帧视频帧，总规模达到近 280 万帧。所有视频均来自 YouTube，涵盖广泛的姿态、年龄、光照、种族和职业分布，具有极高的真实性和多样性。Aff-Wild2 采用逐帧标注方式，为每帧图像提供连续情绪维度标签（Valence 和 Arousal）。该数据集广泛用于跨数据库和数据库内部的深度学习实验，支持联合训练卷积神经网络（CNN）与循环神经网络（RNN）并结合注意力机制，从而同时建模空间特征与行为的时间动态。实验结果表明，Aff-Wild2 及其配套的深度情感建模架构在人类情绪持续建模任务中表现出良好前景，是情感计算与行为分析领域的重要资源。

References：[ Aff-Wild2: Extending the Aff-Wild Database for Affect Recognition](https://arxiv.org/pdf/1811.07770)

~~~~
├──Affwild2
   └── img
       ├── Anger
            ├── 7-60-1920x1080_Train_46to175
                ├── 000001.jpg
                ├── 000002.jpg
                ├── ...
            ├── 7-60-1920x1080_Train_46to175
            ├── 7-60-1920x1080_Train_2337to2480
            ├── ...
       ├── Disgust
       ├── Fear
       ├── Happiness
       ├── Neutral
       ├── Sadness
       ├── Surprise
   └── mp3
       ├── Anger
            ├── 1.mp3
            ├── 2.mp3
            ├── 3.mp3
            ├── ...
       ├── Disgust
       ├── Fear
       ├── Happiness
       ├── Neutral
       ├── Sadness
       ├── Surprise
   └── srt (optional, only for MART)
       ├── Anger
            ├── 1.srt
            ├── 2.srt
            ├── 3.srt
            ├── ...
       ├── Disgust
       ├── Fear
       ├── Happiness
       ├── Neutral
       ├── Sadness
       ├── Surprise
~~~~

## IEMOCAP

IEMOCAP 数据集旨在研究富有表现力的人类交流行为。该数据集由多个受试者参与录制，目的是收集真实、自然的情感表达样本。每个受试者在实验中进行不同情绪状态下的对话表演，涵盖的主要情绪类别包括：快乐、愤怒、悲伤、中性和挫败感。后续情感评估阶段还扩展了厌恶、恐惧、兴奋和惊讶等类别，以更全面地描述自发性场景中的情绪特征。

数据采集过程中，受试者在具有灯光和视觉设计的环境中进行互动，并通过多模态设备记录语音、面部表情和肢体动作。最终的数据形式包括视频、音频、文本转录以及情感标签，适用于情感识别、语音驱动动作生成、虚拟角色行为建模等任务。

References：[IEMOCAP: Interactive emotional dyadic motion capture
database](https://sail.usc.edu/publications/files/bussolre2008.pdf)

~~~~
├──IEMOCAP
   └── img
       ├── Anger
            ├── Ses01F_impro01_F012
                ├── 000001.jpg
                ├── 000002.jpg
                ├── ...
            ├── Ses01F_impro01_M011
            ├── Ses01F_impro01_M013
            ├── ...
       ├── Happy
       ├── Neutral
       ├── Sadness
   └── mp3
       ├── Anger
            ├── 1.mp3
            ├── 2.mp3
            ├── 3.mp3
            ├── ...
       ├── Happy
       ├── Neutral
       ├── Sadness
   └── srt (optional, only for MART)
       ├── Anger
            ├── 1.srt
            ├── 2.srt
            ├── 3.srt
            ├── ...
       ├── Happy
       ├── Neutral
       ├── Sadness
~~~~



## TSL-300

TSL-300 数据集包含 300 个未裁剪视频，平均时长为 4.3 分钟。我们筛除了三种异常视频，以构建高质量且多样化的数据集。所选视频由来自不同背景的四位专业的标注人员进行标注。为减轻密集标注的工作量，我们研究了弱监督和全监督两种训练设置。因此，该数据集包含两种标注类型：逐帧标注（frame-by-frame annotation）和单帧标注（single-frame annotation）。

如果您需要出于学术目的使用 TSL-300 数据集，请下载[申请表](./assets/TSL-300_Data_Access_Form.docx)并填写申请信息，然后发送至 ***gloryzzc6@sina.com***。  
我们将尽快处理您的申请。  
请确保您使用的邮箱为教育机构邮箱。

### Data 准备
1. 准备 [TSL-300](./assets/TSL-300_Data_Access_Form.docx) 数据集  
    - 我们已提供构建好的数据集及预提取的特征。

2. 使用 two-stream I3D 网络提取特征  
    - 我们推荐使用 [该仓库](https://github.com/piergiaj/pytorch-i3d) 提取特征。
    - 为方便起见，我们提供了使用的特征文件，可通过 [百度网盘](https://pan.baidu.com/s/1RHsm3d-ixMhmqmAJsTf3sQ?pwd=jj9w) 下载。
    - 使用以下命令将特征文件夹软链接至 `./dataset/VideoSenti/`：

    ```bash
    sudo ln -s path-to-feature ./dataset/VideoSenti/
    ```

3. 将特征文件放置于 `dataset` 文件夹下  
    - 请确保数据结构如下所示：

~~~~
├── dataset
   └── VideoSenti
       ├── gt.json
       ├── split_train.txt
       ├── split_test.txt
       ├── fps_dict.json
       ├── time.json
       ├── videosenti_gt.json
       ├── point_gaussian
           └── point_labels.csv
           ├── train
       └── features
           ├── train
               ├── rgb
                   ├── 1_Ekman6_disgust_3.npy
                   ├── 2_Ekman6_joy_1308.npy
                   └── ...
               └── logmfcc
                   ├── 1_Ekman6_disgust_3.npy
                   ├── 2_Ekman6_joy_1308.npy
                   └── ...
           └── test
               ├── rgb
                   ├── 9_CMU_MOSEI_lzVA--tIse0.npy
                   ├── 17_CMU_MOSEI_CbRexsp1HKw.npy
                   └── ...
               └── logmfcc
                   ├── 9_CMU_MOSEI_lzVA--tIse0.npy
                   ├── 17_CMU_MOSEI_CbRexsp1HKw.npy
                   └── ...
~~~~

## Emotion-Gait

使用的数据集可在 [Emotion-Gait 官网](https://gamma.umd.edu/software) 获取。

Emotion Gait 数据集包含 2,177 条真实步态和 1,000 条合成步态，涵盖四种情绪类别：高兴、悲伤、愤怒和中性。其中，真实步态包括从现有动作捕捉数据库收集的 1,835 条样本，以及作者自行采集的 342 条样本。1,835 条样本中的每条步态均包含 240 帧，而 342 条样本的帧数范围为 27–75 帧。这些步态的视频 3D 骨骼数据通过代表性的姿态估计方法提取，所有真实步态均由领域专家进行标注。合成步态由输入情绪标签训练得到的自编码器生成。在本研究中，我们仅使用其中的 2,177 条真实步态。

需要注意的是，由于官方网站上的数据集已更新，我们提供原始版本数据集。该代码和数据集仅供科研使用。  
[百度网盘下载链接](https://pan.baidu.com/s/1rNC7SQrwNnZBVMRzPaifZA) (提取码：acil)

请确保数据结构如下所示：

~~~~
BPM_GCN/
├── test_affective.npy
├── test_joint.npy
├── test_label.pkl
├── test_movement.npy
├── train_affective.npy
├── train_joint.npy
├── train_label.pkl
└── train_movement.npy
~~~~
